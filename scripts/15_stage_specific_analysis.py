#!/usr/bin/env python3
"""
ë³‘ê¸°ë³„ ì·Œì¥ì•” ì§„ë‹¨ ì„±ëŠ¥ ë¶„ì„ - íŠ¹íˆ ì´ˆê¸° ì•”(1-2ê¸°) ì§„ë‹¨ìœ¨ í‰ê°€
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (roc_auc_score, roc_curve, classification_report, 
                             confusion_matrix, accuracy_score, precision_score, 
                             recall_score, f1_score)
import warnings
warnings.filterwarnings('ignore')

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path("/home/pjho3/projects/ngs_dss")
RESULTS_DIR = BASE_DIR / "results"
OUTPUT_DIR = RESULTS_DIR / "stage_specific_analysis"
OUTPUT_DIR.mkdir(exist_ok=True)

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("Set2")
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.dpi'] = 300

print("=" * 80)
print("ë³‘ê¸°ë³„ ì·Œì¥ì•” ì§„ë‹¨ ì„±ëŠ¥ ë¶„ì„")
print("=" * 80)

# 1. í†µí•© ë°ì´í„° ë¡œë“œ
print("\n[1] í†µí•© ë°ì´í„° ë¡œë“œ ì¤‘...")
data_file = RESULTS_DIR / "clinical_prediction" / "integrated_data.csv"
df = pd.read_csv(data_file)

print(f"ì „ì²´ ë°ì´í„°: {df.shape}")
print(f"  í™˜ì: {sum(df['label'] == 1)}")
print(f"  ëŒ€ì¡°êµ°: {sum(df['label'] == 0)}")

# 2. ë³‘ê¸°ë³„ ë°ì´í„° ë¶„ì„
print("\n[2] ë³‘ê¸°ë³„ ë°ì´í„° ë¶„ì„...")

# í™˜ìêµ°ë§Œ ì¶”ì¶œ
patient_df = df[df['label'] == 1].copy()

print(f"\ní™˜ìêµ° ë³‘ê¸° ë¶„í¬:")
stage_counts = patient_df['stage'].value_counts().sort_index()
print(stage_counts)

# ê²°ì¸¡ì¹˜ í™•ì¸
print(f"\në³‘ê¸° ê²°ì¸¡ì¹˜: {patient_df['stage'].isna().sum()}ëª…")

# ë³‘ê¸°ë³„ ê·¸ë£¹ ìƒì„±
patient_df['stage_group'] = patient_df['stage'].apply(
    lambda x: 'Early (1-2ê¸°)' if x in [1, 2] else ('Late (3-4ê¸°)' if x in [3, 4] else 'Unknown')
)

print(f"\në³‘ê¸° ê·¸ë£¹ ë¶„í¬:")
print(patient_df['stage_group'].value_counts())

# 3. ì´ˆê¸° ì•”(1-2ê¸°) vs ëŒ€ì¡°êµ° ë¶„ì„
print("\n[3] ì´ˆê¸° ì•”(1-2ê¸°) vs ëŒ€ì¡°êµ° ì§„ë‹¨ ì„±ëŠ¥ ë¶„ì„...")

# ì´ˆê¸° ì•” í™˜ì
early_stage = patient_df[patient_df['stage'].isin([1, 2])].copy()
print(f"\nì´ˆê¸° ì•” í™˜ì: {len(early_stage)}ëª…")

# í›„ê¸° ì•” í™˜ì
late_stage = patient_df[patient_df['stage'].isin([3, 4])].copy()
print(f"í›„ê¸° ì•” í™˜ì: {len(late_stage)}ëª…")

# ëŒ€ì¡°êµ°
normal_df = df[df['label'] == 0].copy()
print(f"ëŒ€ì¡°êµ°: {len(normal_df)}ëª…")

# DMR íŠ¹ì§• ì»¬ëŸ¼
dmr_cols = [col for col in df.columns if col.startswith('DMR_')]
clinical_cols = ['age', 'sex', 'ca19_9']  # stageëŠ” ì œì™¸ (ì˜ˆì¸¡ ëŒ€ìƒì´ë¯€ë¡œ)

print(f"\nDMR íŠ¹ì§• ìˆ˜: {len(dmr_cols)}")

# 4. ëª¨ë¸ 1: ì´ˆê¸° ì•” vs ëŒ€ì¡°êµ°
print("\n" + "=" * 80)
print("ëª¨ë¸ 1: ì´ˆê¸° ì•”(1-2ê¸°) vs ëŒ€ì¡°êµ°")
print("=" * 80)

early_vs_normal = pd.concat([early_stage, normal_df], ignore_index=True)
X_early = early_vs_normal[dmr_cols + clinical_cols].fillna(0)
y_early = early_vs_normal['label']

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
for col in clinical_cols:
    if col in ['sex']:
        X_early[col] = X_early[col].fillna(X_early[col].mode()[0] if len(X_early[col].mode()) > 0 else 1)
    else:
        X_early[col] = X_early[col].fillna(X_early[col].median())

# Cross-validationìœ¼ë¡œ í‰ê°€
scaler_early = StandardScaler()
X_early_scaled = scaler_early.fit_transform(X_early)

lr_early = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Cross-validation ì˜ˆì¸¡
y_pred_early_cv = cross_val_predict(lr_early, X_early_scaled, y_early, cv=cv)
y_prob_early_cv = cross_val_predict(lr_early, X_early_scaled, y_early, cv=cv, method='predict_proba')[:, 1]

# ì„±ëŠ¥ í‰ê°€
acc_early = accuracy_score(y_early, y_pred_early_cv)
auc_early = roc_auc_score(y_early, y_prob_early_cv)
sens_early = recall_score(y_early, y_pred_early_cv)
spec_early = recall_score(y_early, y_pred_early_cv, pos_label=0)
prec_early = precision_score(y_early, y_pred_early_cv)
f1_early = f1_score(y_early, y_pred_early_cv)

print(f"\nì •í™•ë„: {acc_early:.3f}")
print(f"AUC: {auc_early:.3f}")
print(f"ë¯¼ê°ë„ (ì´ˆê¸° ì•” íƒì§€ìœ¨): {sens_early:.3f}")
print(f"íŠ¹ì´ë„: {spec_early:.3f}")
print(f"ì •ë°€ë„: {prec_early:.3f}")
print(f"F1-score: {f1_early:.3f}")

# Confusion Matrix
cm_early = confusion_matrix(y_early, y_pred_early_cv)
print(f"\nConfusion Matrix:")
print(f"  TN: {cm_early[0,0]}, FP: {cm_early[0,1]}")
print(f"  FN: {cm_early[1,0]}, TP: {cm_early[1,1]}")

# 5. ëª¨ë¸ 2: í›„ê¸° ì•” vs ëŒ€ì¡°êµ°
print("\n" + "=" * 80)
print("ëª¨ë¸ 2: í›„ê¸° ì•”(3-4ê¸°) vs ëŒ€ì¡°êµ°")
print("=" * 80)

late_vs_normal = pd.concat([late_stage, normal_df], ignore_index=True)
X_late = late_vs_normal[dmr_cols + clinical_cols].fillna(0)
y_late = late_vs_normal['label']

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
for col in clinical_cols:
    if col in ['sex']:
        X_late[col] = X_late[col].fillna(X_late[col].mode()[0] if len(X_late[col].mode()) > 0 else 1)
    else:
        X_late[col] = X_late[col].fillna(X_late[col].median())

scaler_late = StandardScaler()
X_late_scaled = scaler_late.fit_transform(X_late)

lr_late = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')

y_pred_late_cv = cross_val_predict(lr_late, X_late_scaled, y_late, cv=cv)
y_prob_late_cv = cross_val_predict(lr_late, X_late_scaled, y_late, cv=cv, method='predict_proba')[:, 1]

acc_late = accuracy_score(y_late, y_pred_late_cv)
auc_late = roc_auc_score(y_late, y_prob_late_cv)
sens_late = recall_score(y_late, y_pred_late_cv)
spec_late = recall_score(y_late, y_pred_late_cv, pos_label=0)
prec_late = precision_score(y_late, y_pred_late_cv)
f1_late = f1_score(y_late, y_pred_late_cv)

print(f"\nì •í™•ë„: {acc_late:.3f}")
print(f"AUC: {auc_late:.3f}")
print(f"ë¯¼ê°ë„ (í›„ê¸° ì•” íƒì§€ìœ¨): {sens_late:.3f}")
print(f"íŠ¹ì´ë„: {spec_late:.3f}")
print(f"ì •ë°€ë„: {prec_late:.3f}")
print(f"F1-score: {f1_late:.3f}")

cm_late = confusion_matrix(y_late, y_pred_late_cv)
print(f"\nConfusion Matrix:")
print(f"  TN: {cm_late[0,0]}, FP: {cm_late[0,1]}")
print(f"  FN: {cm_late[1,0]}, TP: {cm_late[1,1]}")

# 6. ì‹œê°í™”
print("\n[6] ì‹œê°í™” ìƒì„± ì¤‘...")

# 6-1. ROC Curve ë¹„êµ
fig, ax = plt.subplots(figsize=(10, 8))

fpr_early, tpr_early, _ = roc_curve(y_early, y_prob_early_cv)
fpr_late, tpr_late, _ = roc_curve(y_late, y_prob_late_cv)

ax.plot(fpr_early, tpr_early, label=f'ì´ˆê¸° ì•”(1-2ê¸°) vs ëŒ€ì¡°êµ° (AUC={auc_early:.3f})', 
        linewidth=3, color='#2ecc71')
ax.plot(fpr_late, tpr_late, label=f'í›„ê¸° ì•”(3-4ê¸°) vs ëŒ€ì¡°êµ° (AUC={auc_late:.3f})', 
        linewidth=3, color='#e74c3c')
ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=2)

ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold')
ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold')
ax.set_title('ROC Curve: ë³‘ê¸°ë³„ ì§„ë‹¨ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold', pad=20)
ax.legend(fontsize=12, loc='lower right')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(OUTPUT_DIR / "roc_curve_by_stage.png", dpi=300, bbox_inches='tight')
print(f"ì €ì¥: {OUTPUT_DIR / 'roc_curve_by_stage.png'}")
plt.close()

# 6-2. ì„±ëŠ¥ ë¹„êµ ë°” ì°¨íŠ¸
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

metrics = ['ì •í™•ë„', 'AUC', 'ë¯¼ê°ë„', 'íŠ¹ì´ë„']
early_scores = [acc_early, auc_early, sens_early, spec_early]
late_scores = [acc_late, auc_late, sens_late, spec_late]

for idx, (ax, metric, early_val, late_val) in enumerate(zip(axes.flat, metrics, early_scores, late_scores)):
    x = ['ì´ˆê¸° ì•”\n(1-2ê¸°)', 'í›„ê¸° ì•”\n(3-4ê¸°)']
    values = [early_val, late_val]
    colors = ['#2ecc71', '#e74c3c']
    
    bars = ax.bar(x, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax.set_ylabel(metric, fontsize=12, fontweight='bold')
    ax.set_ylim([0, 1.1])
    ax.grid(True, alpha=0.3, axis='y')
    
    # ê°’ í‘œì‹œ
    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.suptitle('ë³‘ê¸°ë³„ ì§„ë‹¨ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout()
plt.savefig(OUTPUT_DIR / "performance_by_stage.png", dpi=300, bbox_inches='tight')
print(f"ì €ì¥: {OUTPUT_DIR / 'performance_by_stage.png'}")
plt.close()

# 6-3. Confusion Matrix ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ì´ˆê¸° ì•”
sns.heatmap(cm_early, annot=True, fmt='d', cmap='Greens', ax=axes[0], 
            cbar_kws={'label': 'Count'}, annot_kws={'size': 14, 'weight': 'bold'})
axes[0].set_title(f'ì´ˆê¸° ì•”(1-2ê¸°) vs ëŒ€ì¡°êµ°\në¯¼ê°ë„: {sens_early:.1%}', 
                  fontsize=14, fontweight='bold')
axes[0].set_ylabel('ì‹¤ì œ', fontsize=12, fontweight='bold')
axes[0].set_xlabel('ì˜ˆì¸¡', fontsize=12, fontweight='bold')
axes[0].set_xticklabels(['ëŒ€ì¡°êµ°', 'í™˜ì'])
axes[0].set_yticklabels(['ëŒ€ì¡°êµ°', 'í™˜ì'])

# í›„ê¸° ì•”
sns.heatmap(cm_late, annot=True, fmt='d', cmap='Reds', ax=axes[1], 
            cbar_kws={'label': 'Count'}, annot_kws={'size': 14, 'weight': 'bold'})
axes[1].set_title(f'í›„ê¸° ì•”(3-4ê¸°) vs ëŒ€ì¡°êµ°\në¯¼ê°ë„: {sens_late:.1%}', 
                  fontsize=14, fontweight='bold')
axes[1].set_ylabel('ì‹¤ì œ', fontsize=12, fontweight='bold')
axes[1].set_xlabel('ì˜ˆì¸¡', fontsize=12, fontweight='bold')
axes[1].set_xticklabels(['ëŒ€ì¡°êµ°', 'í™˜ì'])
axes[1].set_yticklabels(['ëŒ€ì¡°êµ°', 'í™˜ì'])

plt.tight_layout()
plt.savefig(OUTPUT_DIR / "confusion_matrix_by_stage.png", dpi=300, bbox_inches='tight')
print(f"ì €ì¥: {OUTPUT_DIR / 'confusion_matrix_by_stage.png'}")
plt.close()

# 7. ê²°ê³¼ ìš”ì•½ ì €ì¥
print("\n[7] ê²°ê³¼ ìš”ì•½ ì €ì¥...")

summary = pd.DataFrame({
    'ë³‘ê¸°': ['ì´ˆê¸° ì•” (1-2ê¸°)', 'í›„ê¸° ì•” (3-4ê¸°)'],
    'í™˜ì ìˆ˜': [len(early_stage), len(late_stage)],
    'ì •í™•ë„': [acc_early, acc_late],
    'AUC': [auc_early, auc_late],
    'ë¯¼ê°ë„': [sens_early, sens_late],
    'íŠ¹ì´ë„': [spec_early, spec_late],
    'ì •ë°€ë„': [prec_early, prec_late],
    'F1-score': [f1_early, f1_late]
})

summary.to_csv(OUTPUT_DIR / "stage_specific_performance.csv", index=False)
print(f"ì €ì¥: {OUTPUT_DIR / 'stage_specific_performance.csv'}")

# ìƒì„¸ ê²°ê³¼
detailed_results = {
    'ì´ˆê¸° ì•” (1-2ê¸°)': {
        'í™˜ì ìˆ˜': len(early_stage),
        'ëŒ€ì¡°êµ° ìˆ˜': len(normal_df),
        'ì •í™•ë„': acc_early,
        'AUC': auc_early,
        'ë¯¼ê°ë„ (ì´ˆê¸° ì•” íƒì§€ìœ¨)': sens_early,
        'íŠ¹ì´ë„': spec_early,
        'ì •ë°€ë„': prec_early,
        'F1-score': f1_early,
        'True Positive': int(cm_early[1,1]),
        'False Negative': int(cm_early[1,0]),
        'True Negative': int(cm_early[0,0]),
        'False Positive': int(cm_early[0,1])
    },
    'í›„ê¸° ì•” (3-4ê¸°)': {
        'í™˜ì ìˆ˜': len(late_stage),
        'ëŒ€ì¡°êµ° ìˆ˜': len(normal_df),
        'ì •í™•ë„': acc_late,
        'AUC': auc_late,
        'ë¯¼ê°ë„ (í›„ê¸° ì•” íƒì§€ìœ¨)': sens_late,
        'íŠ¹ì´ë„': spec_late,
        'ì •ë°€ë„': prec_late,
        'F1-score': f1_late,
        'True Positive': int(cm_late[1,1]),
        'False Negative': int(cm_late[1,0]),
        'True Negative': int(cm_late[0,0]),
        'False Positive': int(cm_late[0,1])
    }
}

detailed_df = pd.DataFrame(detailed_results).T
detailed_df.to_csv(OUTPUT_DIR / "detailed_stage_results.csv")
print(f"ì €ì¥: {OUTPUT_DIR / 'detailed_stage_results.csv'}")

print("\n" + "=" * 80)
print("ë³‘ê¸°ë³„ ë¶„ì„ ì™„ë£Œ!")
print("=" * 80)

print("\nğŸ“Š ì£¼ìš” ê²°ê³¼:")
print(f"\nì´ˆê¸° ì•”(1-2ê¸°) ì§„ë‹¨ ì„±ëŠ¥:")
print(f"  - í™˜ì ìˆ˜: {len(early_stage)}ëª…")
print(f"  - ë¯¼ê°ë„ (ì´ˆê¸° ì•” íƒì§€ìœ¨): {sens_early:.1%}")
print(f"  - AUC: {auc_early:.3f}")
print(f"  - ì •í™•ë„: {acc_early:.1%}")

print(f"\ní›„ê¸° ì•”(3-4ê¸°) ì§„ë‹¨ ì„±ëŠ¥:")
print(f"  - í™˜ì ìˆ˜: {len(late_stage)}ëª…")
print(f"  - ë¯¼ê°ë„ (í›„ê¸° ì•” íƒì§€ìœ¨): {sens_late:.1%}")
print(f"  - AUC: {auc_late:.3f}")
print(f"  - ì •í™•ë„: {acc_late:.1%}")

print(f"\nê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}")
